{
  "7": {
    "inputs": {
      "text": [
        "40",
        0
      ],
      "clip": [
        "11",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  },
  "8": {
    "inputs": {
      "samples": [
        "34",
        0
      ],
      "vae": [
        "37",
        0
      ]
    },
    "class_type": "VAEDecode"
  },
  "9": {
    "inputs": {
      "filename_prefix": "final_output",
      "images": [
        "8",
        0
      ]
    },
    "class_type": "SaveImage"
  },
  "11": {
    "inputs": {
      "lora_01": "None",
      "strength_01": 1,
      "lora_02": "None",
      "strength_02": 1,
      "lora_03": "None",
      "strength_03": 1,
      "lora_04": "None",
      "strength_04": 1,
      "model": [
        "36",
        0
      ],
      "clip": [
        "36",
        1
      ]
    },
    "class_type": "Lora Loader Stack (rgthree)"
  },
  "12": {
    "inputs": {
      "seed": 324975934459406
    },
    "class_type": "Seed (rgthree)"
  },
  "17": {
    "inputs": {
      "width": 4096,
      "height": 4096,
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 4096,
      "target_height": 4096,
      "text_g": [
        "26",
        0
      ],
      "text_l": [
        "26",
        1
      ],
      "clip": [
        "11",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL"
  },
  "21": {
    "inputs": {
      "prompt": "a dog"
    },
    "class_type": "CR Prompt Text"
  },
  "22": {
    "inputs": {
      "prompt": "a dog"
    },
    "class_type": "CR Prompt Text"
  },
  "23": {
    "inputs": {
      "width": 1024,
      "height": 1024,
      "batch_size": 1
    },
    "class_type": "EmptyLatentImage"
  },
  "26": {
    "inputs": {
      "text_positive_g": [
        "21",
        0
      ],
      "text_positive_l": [
        "22",
        0
      ],
      "text_negative": "",
      "style": "base",
      "negative_prompt_to": "Both",
      "log_prompt": "Yes"
    },
    "class_type": "SDXLPromptStylerAdvanced"
  },
  "33": {
    "inputs": {
      "add_noise": "enable",
      "noise_seed": [
        "12",
        0
      ],
      "steps": 40,
      "cfg": 8,
      "sampler_name": "uni_pc",
      "scheduler": "simple",
      "start_at_step": 0,
      "end_at_step": 35,
      "return_with_leftover_noise": "enable",
      "model": [
        "11",
        0
      ],
      "positive": [
        "17",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "23",
        0
      ]
    },
    "class_type": "KSamplerAdvanced"
  },
  "34": {
    "inputs": {
      "add_noise": "disable",
      "noise_seed": [
        "12",
        0
      ],
      "steps": 40,
      "cfg": 8,
      "sampler_name": "uni_pc",
      "scheduler": "simple",
      "start_at_step": 35,
      "end_at_step": 40,
      "return_with_leftover_noise": "enable",
      "model": [
        "35",
        0
      ],
      "positive": [
        "38",
        0
      ],
      "negative": [
        "41",
        0
      ],
      "latent_image": [
        "33",
        0
      ]
    },
    "class_type": "KSamplerAdvanced"
  },
  "35": {
    "inputs": {
      "ckpt_name": "sd_xl_refiner_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "36": {
    "inputs": {
      "ckpt_name": "sd_xl_base_1.0.safetensors"
    },
    "class_type": "CheckpointLoaderSimple"
  },
  "37": {
    "inputs": {
      "vae_name": "sdxl_vae.safetensors"
    },
    "class_type": "VAELoader"
  },
  "38": {
    "inputs": {
      "width": 4096,
      "height": 4096,
      "crop_w": 0,
      "crop_h": 0,
      "target_width": 4096,
      "target_height": 4096,
      "text_g": [
        "26",
        0
      ],
      "text_l": [
        "26",
        1
      ],
      "clip": [
        "35",
        1
      ]
    },
    "class_type": "CLIPTextEncodeSDXL"
  },
  "40": {
    "inputs": {
      "prompt": "text, watermark"
    },
    "class_type": "CR Prompt Text"
  },
  "41": {
    "inputs": {
      "text": [
        "40",
        0
      ],
      "clip": [
        "35",
        1
      ]
    },
    "class_type": "CLIPTextEncode"
  }
}